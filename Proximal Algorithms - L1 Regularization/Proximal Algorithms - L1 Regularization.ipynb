{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximal Algorithms - L1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 采用 L1 正则的求逻辑回归的参数梯度\n",
    "\n",
    "$$\\underset{\\theta}{\\text{min}} \\sum_i^N(y_i-\\sigma(x_i^T\\theta))^2 + \\lambda||\\theta||_1$$\n",
    "\n",
    "\n",
    "2. 简略算法原理\n",
    "\n",
    "    1. proxmial operator 定义\n",
    "        \n",
    "        $$\\text{prox}_f(v) = \\underset{x}{\\text{argmin}}(f(x)+\\frac{1}{2}||x-v||^2_2)$$\n",
    "        \n",
    "    2. 对于 proxmial operator 有一个良好的性质\n",
    "        \n",
    "        $$ x^* = \\underset{x}{\\text{argmin}} f(x) \\text{    当且仅当    } x^* = prox_f(x^*)$$\n",
    "        \n",
    "    3. 对于一个函数 $z$ 由一个可微函数 $f$ 和一个不可微分函数 $g$ 组成，对于 $z$ 有如下定义重要公式\n",
    "        \n",
    "        $$z(x) = f(x) + g(x)$$\n",
    "        \n",
    "        $$x^{k+1} := \\text{prox}_{\\lambda^kg}(x^k - \\lambda^k \\nabla f(x^k))$$\n",
    "        \n",
    "    4. 应用在参数L1参数求解当中 $prox_f(x)$ 中的 $x$ 就是我门需要求的 $\\theta$， $\\lambda^k$ 是学习步长\n",
    "        \n",
    "        $$w:=\\theta^k-\\lambda^k\\nabla f_{\\theta^k}(X)$$\n",
    "        \n",
    "        $$\\theta^{k+1} = \\text{prox}_{{\\lambda^k}g}(w)$$\n",
    "        \n",
    "    5. 求解上面式子的结果，$\\lambda$ 是 L1 正则的惩罚系数，$\\lambda^k$ 是学习步长，$\\theta$ 是一个向量\n",
    "    \n",
    "        $$[\\theta^{k+1}]_i=\\left\\{\\begin{aligned}\n",
    "        w_i - \\lambda\\lambda^k, & \\text{ if } & w_i > \\lambda\\lambda^k\\\\\n",
    "        0, & \\text{ if } & \\lambda\\lambda^k < w_i < -\\lambda\\lambda^k\\\\\n",
    "        w_i + \\lambda\\lambda^k, & \\text{ if } & w_i < -\\lambda\\lambda^k\\\\\n",
    "                                  \\end{aligned}\\right.$$\n",
    "                                                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. 详细证明过程附件中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "from jax import grad, vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated theta [2. 2. 0. 0. 0.]\n",
      "initial theta [ 0.18784378 -1.2833427  -0.27109176  1.2490592   0.24446994]\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "x = jax.random.normal(key, (1000,5))\n",
    "true_theta = jnp.array([2.0, 2.0, 0.0, 0.0, 0.0])\n",
    "theta = jax.random.normal(key, (5, ))\n",
    "y = (jnn.sigmoid(jnp.dot(x, true_theta)) >= 0.5).astype(jnp.float32)\n",
    "\n",
    "print('generated theta', true_theta)\n",
    "print('initial theta', theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, x):\n",
    "    return jnn.sigmoid(jnp.dot(x, theta))\n",
    "\n",
    "def get_lr_grad(theta, x, y_true):\n",
    "    y_pre = predict(theta, x)\n",
    "    return jnp.dot(x.T, y_pre - y_true) / x.shape[0]\n",
    "\n",
    "def get_lr_loss(theta, x, y_true):\n",
    "    y_pre = predict(theta, x)\n",
    "    return -jnp.mean(y_true * jnp.log(y_pre) + (1 - y_true) * jnp.log(1 - y_pre))\n",
    "\n",
    "\n",
    "def soft_threshold(vec_theta, threshold):\n",
    "    new_vec_theta = []\n",
    "\n",
    "    for theta in vec_theta:\n",
    "        if theta > threshold:\n",
    "            new_vec_theta.append(theta - threshold)\n",
    "        elif theta < -threshold:\n",
    "            new_vec_theta.append(theta + threshold)\n",
    "        else:\n",
    "            new_vec_theta.append(0)\n",
    "    \n",
    "    return jnp.array(new_vec_theta)\n",
    "    \n",
    "\n",
    "def proximal_method_update(theta, x, y_true, lr, penalty):\n",
    "    w = theta - lr * get_lr_grad(theta, x, y_true)\n",
    "    new_theta = soft_threshold(w, lr * penalty)\n",
    "\n",
    "    return jnp.array(new_theta)\n",
    "\n",
    "\n",
    "def model_train(theta, x, y_true, lr, penalty, esp, max_iter):\n",
    "    current_iter, current_esp = 1, 1\n",
    "    \n",
    "    while max_iter > current_iter and current_esp > esp:\n",
    "        \n",
    "        loss = get_lr_loss(theta, x, y_true) + penalty * jnp.linalg.norm(theta, 1)\n",
    "        new_theta = proximal_method_update(theta, x, y_true, lr, penalty)\n",
    "        current_esp = jnp.mean(jnp.abs(new_theta - theta))\n",
    "        \n",
    "        theta = new_theta\n",
    "        current_iter += 1\n",
    "        \n",
    "#         print('{}  loss: {:.4f} theta: {}'.format(current_iter-1, loss, theta))\n",
    "\n",
    "    return new_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.99816716, 0.91049355, 0.        , 0.        , 0.        ],            dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.05\n",
    "penalty = 0.1\n",
    "esp = 1e-4\n",
    "max_iter = 3000\n",
    "\n",
    "proximal_method_theta = model_train(theta, x, y, lr, penalty, esp, max_iter)\n",
    "proximal_method_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Jax Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@grad\n",
    "def jax_lr_loss(theta, x, y):\n",
    "    y_pre = jnn.sigmoid(jnp.dot(x, theta))\n",
    "    return -(jnp.mean(y*jnp.log(y_pre) + (1-y)*jnp.log(1-y_pre)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-0.24260923, -0.4717243 , -0.08309114,  0.1896846 ,\n",
       "              0.04510983], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax_lr_loss(theta, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-0.24260938, -0.47172442, -0.08309112,  0.1896846 ,\n",
       "              0.04510981], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lr_grad(theta,x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
