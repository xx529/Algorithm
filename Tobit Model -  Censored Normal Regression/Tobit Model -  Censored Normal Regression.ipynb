{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Tobit Model -  Censored Normal Regression.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xx529/Algorithm/blob/main/Tobit%20Model%20-%20%20Censored%20Normal%20Regression/Tobit%20Model%20-%20%20Censored%20Normal%20Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kof3fOwQ1TA"
      },
      "source": [
        "# Tobit Model -  Censored Normal Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaDaWXhxQ1TC"
      },
      "source": [
        "**关于算法的故事**\n",
        "\n",
        "在任一给定年份，有相当数量家庭的医疗保险费用支出为0\n",
        "\n",
        "因此，虽然年度家庭医疗保险费用支出的总体分布散布于一个很大的正数范围内，但在数字0上却相当集中"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq_7TwqFQ1TD"
      },
      "source": [
        "# Algorithm\n",
        "\n",
        "**定义**\n",
        "\n",
        "1. 因变量 $y$ 在正值上大致是连续分布，但也包含一部分以正概率取值为0的观测，对于 $y$ 如下定义，$y^*$ 是一个隐藏的变量，它与0共同决定了观测 $y$\n",
        "\n",
        "$$y=\\left\\{\n",
        "\\begin{aligned}\n",
        "y^* ,& y^* \\geqslant 0 \\\\\n",
        "- ,& y^* < 0 \n",
        "\\end{aligned}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "2. 隐藏变量 $y^*$ 由一个参数为 $\\beta$ 的线性方程和 $\\epsilon$，定义如下\n",
        "2\n",
        "$$y^* = x^T\\beta + \\epsilon, \\text{ 其中 } \\epsilon \\sim N(0, \\sigma^2)$$\n",
        "$$$$\n",
        "\n",
        "3. 需要优化的参数就是 $\\beta$ 和 $\\sigma$\n",
        "\n",
        "$$\\hat{\\theta}= (\\hat{\\beta}, \\hat{\\sigma}^2)$$\n",
        "\n",
        "**目标函数**\n",
        "\n",
        "1. 定义一个 indicator variable $d$，取 $L=0$ 如下:\n",
        "\n",
        "$$d=\\left\\{\n",
        "\\begin{aligned}\n",
        "1 ,& y > L\\\\\n",
        "0 ,& y = L \n",
        "\\end{aligned}\n",
        "\\right.$$\n",
        "\n",
        "2. 由定义式可知 $y^* \\sim (x^T\\beta, \\sigma^2)$\n",
        "\n",
        "$$y^* = x^T\\beta + \\epsilon \\rightarrow y^* \\sim (x^T\\beta, \\sigma^2)$$\n",
        "\n",
        "3. 当 $y^*<L$，用 CDF概率分布函数，当 $y^*>L$ 可观测时候用 PDF概率密度函数，这里取 $L=0$\n",
        "\n",
        "$$f(y)=\\left\\{\n",
        "\\begin{aligned} F^*(0)=1-\\Phi(\\frac{x^T\\beta}{\\sigma}), d=0\\\\\n",
        "\\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{1}{2\\sigma^2}(y-x^T\\beta)^2), d=1\n",
        "\\end{aligned}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "4. 综合上面两个分段函数就有如下形式，也就是我们通过 MLE 最大化的函数\n",
        "\n",
        "$$f(y) =[\\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(-\\frac{1}{2\\sigma^2}(y-x^T\\beta)^2)]^d[1-\\Phi(\\frac{x^T\\beta}{\\sigma})]^{1-d}$$\n",
        "\n",
        "**参数梯度**\n",
        "\n",
        "对以上公式取 $log$ 之后的参数梯度，其中 $\\phi_i=\\phi(\\frac{x_i^T\\beta}{\\sigma})$，$\\Phi_i=\\Phi(\\frac{x_i^T\\beta}{\\sigma})$\n",
        "\n",
        "$$\\frac{\\partial ln L_N}{\\partial \\beta}=\\sum^N_{i=1}\\frac{1}{\\sigma^2}(d_i(y_i-x^T\\beta)-(1-d_i)\\frac{\\sigma\\phi_i}{1-\\Phi_i})x_i$$\n",
        "\n",
        "\n",
        "$$\\frac{\\partial ln L_N}{\\partial \\sigma^2}=\\sum^N_{i=1}[d_i(-\\frac{1}{2\\sigma^2}+\\frac{(y_i-x^T\\beta)^2}{2\\sigma^4})+(1-d_i)\\frac{\\phi_ix_i^T\\beta}{1-\\Phi_i} · \\frac{1}{2\\sigma^3}]$$\n",
        "\n",
        "**优化方法**\n",
        "\n",
        "[Proximal Methods](https://github.com/xx529/Algorithm/blob/main/Proximal%20Algorithms%20-%20L1%20Regularization/Proximal%20Algorithms%20-%20L1%20Regularization.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RiuZETpQ1TE"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, vmap, jit\n",
        "from jax.lax import cond\n",
        "import numpy as np"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPO65iEWQ1TF"
      },
      "source": [
        "# Experiment Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG_Q5KdWQ1TF",
        "outputId": "03d5b87f-58b3-46b5-bcef-4f5fc046aff8"
      },
      "source": [
        "key = jax.random.PRNGKey(529)\n",
        "batch = 10000\n",
        "input_dim = 4\n",
        "L = 0\n",
        "\n",
        "true_beta = jnp.array([2.0, 3.0, -2.0, 0.0])\n",
        "true_sigma = 2.0\n",
        "epsilon = jax.random.normal(key, (batch, )) * (true_sigma**2)\n",
        "\n",
        "x = jax.random.normal(key, (batch, input_dim))\n",
        "y_star = jnp.dot(x, true_beta) + epsilon\n",
        "d = (y_star > L).astype(jnp.float32)\n",
        "y =  d * y_star\n",
        "\n",
        "beta = jax.random.normal(key, (input_dim, ))\n",
        "sigma = jax.random.normal(key)\n",
        "\n",
        "print('epsilon mean', epsilon.mean())\n",
        "print('epsilon std', epsilon.std())\n",
        "print('y_star std', y_star.std())\n",
        "print('x_dot_b mean', jnp.dot(x, true_beta).mean())\n",
        "print('y_star mean', y_star.mean())"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epsilon mean -0.011463349\n",
            "epsilon std 4.009254\n",
            "y_star std 5.6949024\n",
            "x_dot_b mean -0.0027797106\n",
            "y_star mean -0.014243055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CviwImsBQ1TG",
        "outputId": "8afba00e-fbba-4af0-9fb5-871fdad37c51"
      },
      "source": [
        "y"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([-0.        ,  1.8103466 , -0.        , ..., -0.        ,\n",
              "              0.15429918, -0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buaAoUKQQ1TG",
        "outputId": "af3ca20c-8008-4198-90c0-06ad6f4b087b"
      },
      "source": [
        "y_star"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([ -1.7571797 ,   1.8103466 ,  -9.282396  , ...,  -6.6482935 ,\n",
              "               0.15429918, -10.751861  ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKbjrrAeQ1TE"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnuFd-KVQ1TH"
      },
      "source": [
        "### General Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qPm6IEGQ1TH"
      },
      "source": [
        "def normal_cdf(x):\n",
        "    return jax.scipy.stats.norm.cdf(x, loc=0, scale=1)\n",
        "\n",
        "\n",
        "def normal_pdf(x):\n",
        "    return jax.scipy.stats.norm.pdf(x, loc=0, scale=1)\n",
        "\n",
        "\n",
        "def linear(x, beta):\n",
        "    return jnp.dot(x, beta)\n",
        "\n",
        "\n",
        "def log_mle(x, beta, sigma, y_true, l):\n",
        "    d = (y_true > l).astype(jnp.float32)\n",
        "    temp1 = d * jnp.log(1 / (jnp.sqrt(2 * jnp.pi * sigma**2))) + (-1 / (2 * sigma**2)) * (y_true - linear(x, beta))**2\n",
        "    temp2 = (1 - d) * jnp.log(1 - normal_cdf(linear(x, beta) / sigma) + 0.01)\n",
        "    return jnp.mean(temp1 + temp2)\n",
        "\n",
        "\n",
        "def tobit_model_grad(x, y_true, beta, sigma):\n",
        "    x_dot_beta = linear(x, beta)\n",
        "    residual = y_true - x_dot_beta\n",
        "    sigma_square = sigma**2\n",
        "    cdf = normal_cdf(x_dot_beta / sigma)\n",
        "    pdf = normal_pdf(x_dot_beta / sigma)\n",
        "    d = (y_true > L).astype(jnp.float32)\n",
        "    \n",
        "    d_beta_temp = d*residual - (1-d) * sigma * pdf / (1 - cdf + 0.01)\n",
        "    d_beta = - (1 / sigma_square) * jnp.dot(d_beta_temp, x) / x.shape[0]\n",
        "    \n",
        "    d_sigma2_temp_1 = d * (-1 / (2 * sigma_square) + (residual**2) / (2 * sigma**4))    \n",
        "    d_sigma2_temp_2 = 1 / (2 * sigma**3 ) * (1 - d) * (pdf * x_dot_beta) / (1 - cdf + 0.01)\n",
        "    d_sigma2 = - jnp.mean(d_sigma2_temp_1 + d_sigma2_temp_2)\n",
        "    \n",
        "    return d_beta, d_sigma2\n",
        "\n",
        "\n",
        "def tobit_model_train(x, y_true, beta, sigma, lr, l, esp, max_iter):\n",
        "    current_mle, current_esp, current_iter = jnp.inf, 1, 1\n",
        "\n",
        "    while current_iter <= max_iter and current_esp >= esp:\n",
        "        d_beta, d_sigma2 = jit(tobit_model_grad)(x, y, beta, sigma)\n",
        "\n",
        "        beta = beta - lr * d_beta\n",
        "        sigma = jnp.sqrt(sigma**2 - lr * d_sigma2)\n",
        "\n",
        "        mle = log_mle(x, beta, sigma, y_true, l)\n",
        "        current_esp = jnp.abs(mle - current_mle)\n",
        "        current_mle = mle\n",
        "        current_iter += 1\n",
        "\n",
        "    return beta, sigma"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I78MPsSPbSM"
      },
      "source": [
        "### JAX Version\n",
        "1. Proximal Method\n",
        "2. Accelerated by jit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRASvNkd74vF"
      },
      "source": [
        "def normal_cdf(x):\n",
        "    return jax.scipy.stats.norm.cdf(x, loc=0, scale=1)\n",
        "\n",
        "\n",
        "def normal_pdf(x):\n",
        "    return jax.scipy.stats.norm.pdf(x, loc=0, scale=1)\n",
        "\n",
        "\n",
        "def linear(x, beta):\n",
        "    return jnp.dot(x, beta)\n",
        "\n",
        "\n",
        "def log_mle(x, beta, sigma, y_true, l):\n",
        "    d = (y_true > l).astype(jnp.float32)\n",
        "    temp1 = d * jnp.log(1 / (jnp.sqrt(2 * jnp.pi * sigma**2))) + (-1 / (2 * sigma**2)) * (y_true - linear(x, beta))**2\n",
        "    temp2 = (1 - d) * jnp.log(1 - normal_cdf(linear(x, beta) / sigma) + 0.01)\n",
        "    return jnp.mean(temp1 + temp2)\n",
        "\n",
        "\n",
        "@jax.partial(vmap, in_axes=(0, 0, None, None, None))\n",
        "def select_grad(x, y_true, beta, sigma, L):\n",
        "    return jax.lax.cond(\n",
        "        y_true > L,\n",
        "        lambda _: ( # > L\n",
        "            - 1 / (sigma**2) * jnp.dot((y_true - linear(x, beta)), x), # beta\n",
        "            - (- 1 / (2*sigma**2) + (y_true - linear(x, beta))**2 / (2 * sigma**4)) # sigma\n",
        "        ), \n",
        "        lambda _: ( # < L\n",
        "             1 / (sigma**2) * jnp.dot((sigma * normal_pdf(linear(x, beta) / sigma) / (1 - normal_cdf(linear(x, beta) / sigma) + 0.01)), x), # beta\n",
        "            - 1 / (2 * sigma**3) * normal_pdf(linear(x, beta) / sigma) * linear(x, beta) / (1 - normal_cdf(linear(x, beta) / sigma) + 0.01) # sigma\n",
        "        ), \n",
        "        operand = None\n",
        "    )\n",
        "\n",
        "\n",
        "def jax_soft_threshold(w, threshold):\n",
        "    return jax.lax.cond(\n",
        "        w > threshold, \n",
        "        lambda _: w - threshold,\n",
        "        lambda _: jax.lax.cond(\n",
        "            w < - threshold,\n",
        "            lambda _: w + threshold,\n",
        "            lambda _: 0.0,\n",
        "            None\n",
        "            ),\n",
        "        None\n",
        "        )\n",
        "    \n",
        "\n",
        "def jax_proximal_method_update(beta, sigma, x, y_true, l, lr, penalty):\n",
        "    d_beta, d_sigma2 = select_grad(x, y_true, beta, sigma, l)\n",
        "    w_beta = beta - lr * jnp.mean(d_beta, axis=0)\n",
        "    w_sigma = jnp.sqrt(sigma**2 - lr * jnp.mean(d_sigma2))\n",
        "\n",
        "    return vmap(jax_soft_threshold, in_axes=(0, None))(w_beta, lr * penalty), jax_soft_threshold(w_sigma, lr * penalty)\n",
        "\n",
        "\n",
        "def cond_fun(val):\n",
        "    x, y_true, beta, sigma, lr, L, penalty, current_iter, max_iter, current_mle, current_esp, esp = val\n",
        "    result = val[7] <= val[8]\n",
        "    # result = (val[8] > val[9]) \n",
        "    return result\n",
        "\n",
        "\n",
        "def body_fun(val):\n",
        "    x, y_true, beta, sigma, lr, L, penalty, current_iter, max_iter, current_mle, current_esp, esp = val\n",
        "\n",
        "    new_beta, new_sigma = jax_proximal_method_update(beta, sigma, x, y_true, L, lr, penalty)\n",
        "\n",
        "    new_mle = log_mle(x, new_beta, new_sigma, y_true, L)\n",
        "    current_esp = jnp.abs(current_mle - new_mle)\n",
        "    current_iter += 1\n",
        "\n",
        "    return (x, y_true, new_beta, new_sigma, lr, L, penalty, current_iter, max_iter, new_mle, current_esp, esp)\n",
        "\n",
        "\n",
        "@jit\n",
        "def jax_tobit_model_train(init_val):\n",
        "    return jax.lax.while_loop(cond_fun, body_fun, init_val)"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAfAlWfFiX-g"
      },
      "source": [
        "# Code Test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjj4DjJy8ed7"
      },
      "source": [
        "lr = 1e-3\n",
        "esp = 1e-6\n",
        "max_iter = 10000\n",
        "current_iter = 1\n",
        "current_mle = log_mle(x, beta, sigma, y, L)\n",
        "last_mle = log_mle(x, beta, sigma, y, L) + 1\n",
        "current_esp = jnp.abs(current_mle - last_mle) "
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX-JEBdQ9ZbE",
        "outputId": "bef81c67-2f02-4745-fdcb-bc713d35825a"
      },
      "source": [
        "print(true_beta)\n",
        "print(true_sigma)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2.  3. -2.  0.]\n",
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTRcGjGL8jSf",
        "outputId": "bec26c4f-bc0f-4083-e492-d60b20ab13ec"
      },
      "source": [
        "%%time\n",
        "result = tobit_model_train(x, y, beta, sigma, lr, L, esp, max_iter)\n",
        "print(result[0])\n",
        "print(result[1])"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.553281   1.6745833 -1.7175509  0.0360731]\n",
            "2.4013102\n",
            "CPU times: user 2min 20s, sys: 28.5 s, total: 2min 49s\n",
            "Wall time: 1min 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-4r_neVYZSx",
        "outputId": "c8081c27-2791-4206-b84e-e3fa08207bf7"
      },
      "source": [
        "%%time\n",
        "penalty = 0.00\n",
        "\n",
        "init_val = (x, y, beta, sigma, lr, L, penalty, current_iter, max_iter, current_mle, current_esp, esp)\n",
        "result = jax_tobit_model_train(init_val)\n",
        "\n",
        "print(result[2])\n",
        "print(result[3])"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.553281    1.6745833  -1.7175509   0.03607311]\n",
            "2.4013102\n",
            "CPU times: user 1.27 s, sys: 273 ms, total: 1.55 s\n",
            "Wall time: 1.55 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flp5EAzkYZ93",
        "outputId": "b6473982-451b-4428-875b-9d86af82b2c2"
      },
      "source": [
        "%%time\n",
        "penalty = 0.05\n",
        "\n",
        "init_val = (x, y, beta, sigma, lr, L, penalty, current_iter, max_iter, current_mle, current_esp, esp)\n",
        "result = jax_tobit_model_train(init_val)\n",
        "\n",
        "print(result[2])\n",
        "print(result[3])"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.3104256  1.6382418 -1.4624276  0.       ]\n",
            "2.081685\n",
            "CPU times: user 1.2 s, sys: 335 ms, total: 1.54 s\n",
            "Wall time: 1.54 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5njmTjFWLkaX",
        "outputId": "143d0b42-7b90-428e-b92a-d612a52e0d36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "penalty = 0.1\n",
        "\n",
        "init_val = (x, y, beta, sigma, lr, L, penalty, current_iter, max_iter, current_mle, current_esp, esp)\n",
        "result = jax_tobit_model_train(init_val)\n",
        "\n",
        "print(result[2])\n",
        "print(result[3])"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.1199226  1.597426  -1.2620401  0.       ]\n",
            "1.8571857\n",
            "CPU times: user 1.27 s, sys: 276 ms, total: 1.55 s\n",
            "Wall time: 1.55 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6hh-8PyRdyY"
      },
      "source": [
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VdyukgBBHbF"
      },
      "source": [
        "# Others\n",
        "* 检查当 ϵ 为柯西分布时对整个估计的影响\n",
        "* 对参数估计整体偏小"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W79VUwFABJZB"
      },
      "source": [
        "key = jax.random.PRNGKey(300)\n",
        "batch = 10000\n",
        "input_dim = 6\n",
        "L = 0\n",
        "\n",
        "true_beta = jnp.array([2.0, 3.0, -2.0, 0.0, 3.0, 5.0])\n",
        "cauchy_epsilon = jax.random.cauchy(key,(batch, ))\n",
        "\n",
        "cauchy_x = jax.random.normal(key, (batch, input_dim))\n",
        "cauchy_y_star = jnp.dot(cauchy_x, true_beta) + cauchy_epsilon\n",
        "cauchy_d = (cauchy_y_star > L).astype(jnp.float32)\n",
        "cauchy_y =  d * cauchy_y_star\n",
        "\n",
        "cauchy_beta = jax.random.normal(key, (input_dim, ))\n",
        "cauchy_sigma = jax.random.normal(key)"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0O6DOZ0D4AY",
        "outputId": "ba58324b-9c3a-4b0f-8ca6-923815e2e544",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "true_beta"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([ 2.,  3., -2.,  0.,  3.,  5.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exk_0hwAEBXq",
        "outputId": "6231a899-4d69-4ac9-9596-628013a66c7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr = 1e-3\n",
        "esp = 1e-6\n",
        "max_iter = 10000\n",
        "current_iter = 1\n",
        "current_mle = log_mle(x, beta, sigma, y, L)\n",
        "last_mle = log_mle(x, beta, sigma, y, L) + 1\n",
        "current_esp = jnp.abs(current_mle - last_mle) \n",
        "penalty = 0.0\n",
        "\n",
        "init_val = (cauchy_x, cauchy_y, cauchy_beta, cauchy_sigma, lr, L, penalty, current_iter, max_iter, current_mle, current_esp, esp)\n",
        "result = jax_tobit_model_train(init_val)\n",
        "print(result[2])\n",
        "print(result[3])"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.4167621  0.5719836 -0.3839866  0.1592816  1.8818617  1.4384959]\n",
            "3.8122559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6R76yzeIm7a",
        "outputId": "57f7553f-d4aa-428d-d33c-74f2dfe71d28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr = 1e-3\n",
        "esp = 1e-6\n",
        "max_iter = 20000\n",
        "current_iter = 1\n",
        "current_mle = log_mle(x, beta, sigma, y, L)\n",
        "last_mle = log_mle(x, beta, sigma, y, L) + 1\n",
        "current_esp = jnp.abs(current_mle - last_mle) \n",
        "penalty = 0.00\n",
        "\n",
        "init_val = (cauchy_x, cauchy_y, cauchy_beta, cauchy_sigma, lr, L, penalty, current_iter, max_iter, current_mle, current_esp, esp)\n",
        "result = jax_tobit_model_train(init_val)\n",
        "print(result[2])\n",
        "print(result[3])"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.2742995   0.78964996 -0.6868022  -0.00281969  1.7733035   1.7916064 ]\n",
            "4.2732177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Rtn9acNo1q",
        "outputId": "85155b9b-f454-4a44-b68c-02f5990a61a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr = 1e-3\n",
        "esp = 1e-6\n",
        "max_iter = 30000\n",
        "current_iter = 1\n",
        "current_mle = log_mle(x, beta, sigma, y, L)\n",
        "last_mle = log_mle(x, beta, sigma, y, L) + 1\n",
        "current_esp = jnp.abs(current_mle - last_mle) \n",
        "penalty = 0.00\n",
        "\n",
        "init_val = (cauchy_x, cauchy_y, cauchy_beta, cauchy_sigma, lr, L, penalty, current_iter, max_iter, current_mle, current_esp, esp)\n",
        "result = jax_tobit_model_train(init_val)\n",
        "print(result[2])\n",
        "print(result[3])"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.1933279   0.92393094 -0.8688001  -0.09837008  1.7164546   2.0070918 ]\n",
            "4.568091\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}